{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# webcraweler with python example\n",
    "\n",
    "## 1. picture downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import time\n",
    "from pandas import DataFrame\n",
    "import  pandas  as pd\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 create header infomation\n",
    "header = {\n",
    "'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.143 Safari/537.36',\n",
    "'Connection': 'keep-alive',\n",
    "'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find a HTTP headers in Google Chrome, take the following steps :\n",
    "\n",
    "1. In Chrome, visit a URL, right click, select Inspect to open the developer tools.\n",
    "2. Select Network tab.\n",
    "3. Reload the page, select any HTTP request on the left panel, and the HTTP headers will be displayed on the right panel.\n",
    "4.  filters are set to “All” to the right of the to the “Hide Data URLs” check box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "https://img.dpm.org.cn/Uploads/Picture/2019/09/28/s5d8f20c646f5b.jpg\n",
      "start saving\n",
      "./img/1.jpg succesfully saved！\n",
      "https://img.dpm.org.cn/Uploads/Picture/2019/09/27/s5d8d92aa77c1d.jpg\n",
      "start saving\n",
      "./img/2.jpg succesfully saved！\n",
      "https://img.dpm.org.cn/Uploads/Picture/2019/09/27/s5d8d75558e494.jpg\n",
      "start saving\n",
      "./img/3.jpg succesfully saved！\n",
      "https://img.dpm.org.cn/Uploads/Picture/2019/09/27/s5d8d6e3349b24.jpg\n",
      "start saving\n",
      "./img/4.jpg succesfully saved！\n",
      "https://img.dpm.org.cn/Uploads/Picture/2019/08/27/s5d64e6209d5a8.jpg\n",
      "start saving\n",
      "./img/5.jpg succesfully saved！\n",
      "https://img.dpm.org.cn/Uploads/Picture/2019/08/27/s5d64d8d6d0e41.jpg\n",
      "start saving\n",
      "./img/6.jpg succesfully saved！\n",
      "https://img.dpm.org.cn/Uploads/Picture/2019/08/27/s5d64d5b244ab8.jpg\n",
      "start saving\n",
      "./img/7.jpg succesfully saved！\n",
      "https://img.dpm.org.cn/Uploads/Picture/2019/08/27/s5d64d1fd4f99f.jpg\n",
      "start saving\n",
      "./img/8.jpg succesfully saved！\n",
      "https://img.dpm.org.cn/Uploads/Picture/2019/08/27/s5d64cc4a7ede2.jpg\n",
      "start saving\n",
      "./img/9.jpg succesfully saved！\n",
      "1\n",
      "https://img.dpm.org.cn/Uploads/Picture/2019/08/07/s5d4a770b45dc3.jpg\n",
      "start saving\n",
      "./img/10.jpg succesfully saved！\n",
      "https://img.dpm.org.cn/Uploads/Picture/2019/07/31/s5d40f3342e75d.jpg\n",
      "start saving\n",
      "./img/11.jpg succesfully saved！\n",
      "https://img.dpm.org.cn/Uploads/Picture/2019/07/31/s5d415b7756cfd.jpg\n",
      "start saving\n",
      "./img/12.jpg succesfully saved！\n",
      "https://img.dpm.org.cn/Uploads/Picture/2019/07/31/s5d40ee7d8c07a.jpg\n",
      "start saving\n",
      "./img/13.jpg succesfully saved！\n",
      "https://img.dpm.org.cn/Uploads/Picture/2019/07/31/s5d40ecd4177d1.jpg\n",
      "start saving\n",
      "./img/14.jpg succesfully saved！\n",
      "https://img.dpm.org.cn/Uploads/Picture/2019/06/30/s5d187e8c6ae17.jpg\n",
      "start saving\n",
      "./img/15.jpg succesfully saved！\n",
      "https://img.dpm.org.cn/Uploads/Picture/2019/06/30/s5d187ca890757.jpg\n",
      "start saving\n",
      "./img/16.jpg succesfully saved！\n",
      "https://img.dpm.org.cn/Uploads/Picture/2019/06/30/s5d187b65096d1.jpg\n",
      "start saving\n",
      "./img/17.jpg succesfully saved！\n",
      "https://img.dpm.org.cn/Uploads/Picture/2019/06/30/s5d187a6bdde6f.jpg\n",
      "start saving\n",
      "./img/18.jpg succesfully saved！\n"
     ]
    }
   ],
   "source": [
    "header = {
'Referer': 'http://www.nysm.nysed.gov/exhibitions',
'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.132 Safari/537.36'
}
"import requests
"from bs4 import BeautifulSoup
#url_path = 'https://www.dpm.org.cn/lights/royal/p/'
"url = 'http://www.nysm.nysed.gov/exhibitions'
"url_all=[]
"j = 0
"data = requests.get(url,headers=header).content.decode('utf8')
"soup = BeautifulSoup(data,'html.parser')   
"urldiv = soup.find_all('div',{'class':'medium-12 exhibition-thumb'}) 
"#print(urldiv)      

"for urltemp in urldiv:
    "url_find = urltemp.img['src']
    "url_all.append(url_find)
    "j = j+1
    "#new_url = url_find[:4]+url_find[5:]
    "print(url_find)      
    "imgs = requests.get(url_find,headers=header)     
    "file_name = "./img/"+str(j)+"new.jpg"
    "print('start downloading images') 
    "f = open(file_name, 'ab') 
    "f.write(imgs.content) 
    "print(file_name, 'succesffully saved！') 
    "f.close()
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# practice1 \n",
    "try another website：http://www.nysm.nysed.gov/exhibitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.nysm.nysed.gov/common/nysm/files/styles/500px_square/public/woodstock-arthuranderson.jpg?itok=7WEZKra5\n",
      "start downloading images\n",
      "./img/1new.jpg succesffully saved！\n",
      "http://www.nysm.nysed.gov/common/nysm/files/styles/500px_square/public/stanton-anthony.jpg?itok=zWN4TsYK\n",
      "start downloading images\n",
      "./img/2new.jpg succesffully saved！\n",
      "http://www.nysm.nysed.gov/common/nysm/files/styles/500px_square/public/fortorange.jpg?itok=g7RcGFP5\n",
      "start downloading images\n",
      "./img/3new.jpg succesffully saved！\n",
      "http://www.nysm.nysed.gov/common/nysm/files/styles/500px_square/public/erie-canal-th.jpg?itok=xu3l860c\n",
      "start downloading images\n",
      "./img/4new.jpg succesffully saved！\n",
      "http://www.nysm.nysed.gov/common/nysm/files/styles/500px_square/public/adirondackwilderness-th_1.jpg?itok=IEL90g0u\n",
      "start downloading images\n",
      "./img/5new.jpg succesffully saved！\n",
      "http://www.nysm.nysed.gov/common/nysm/files/styles/500px_square/public/weitsman-th.jpg?itok=QTS8HWlF\n",
      "start downloading images\n",
      "./img/6new.jpg succesffully saved！\n",
      "http://www.nysm.nysed.gov/common/nysm/files/styles/500px_square/public/beneathcity-excavation_1.jpg?itok=y_L0WSnQ\n",
      "start downloading images\n",
      "./img/7new.jpg succesffully saved！\n",
      "http://www.nysm.nysed.gov/common/nysm/files/styles/500px_square/public/Bluebird_1.jpg?itok=vEVJcsUy\n",
      "start downloading images\n",
      "./img/8new.jpg succesffully saved！\n",
      "http://www.nysm.nysed.gov/common/nysm/files/styles/500px_square/public/blackharlem-statue_1.jpg?itok=BGzt95u7\n",
      "start downloading images\n",
      "./img/9new.jpg succesffully saved！\n",
      "http://www.nysm.nysed.gov/common/nysm/files/styles/500px_square/public/mastodon-sq_2.jpg?itok=MxnDDzFR\n",
      "start downloading images\n",
      "./img/10new.jpg succesffully saved！\n",
      "http://www.nysm.nysed.gov/common/nysm/files/styles/500px_square/public/map-highlight2_0.jpg?itok=Kqyuvpc-\n",
      "start downloading images\n",
      "./img/11new.jpg succesffully saved！\n",
      "http://www.nysm.nysed.gov/common/nysm/files/styles/500px_square/public/fire-main.jpg?itok=iuoLIlrK\n",
      "start downloading images\n",
      "./img/12new.jpg succesffully saved！\n",
      "http://www.nysm.nysed.gov/common/nysm/files/styles/500px_square/public/iceages-sq.jpg?itok=Zy7pD6w5\n",
      "start downloading images\n",
      "./img/13new.jpg succesffully saved！\n",
      "http://www.nysm.nysed.gov/common/nysm/files/styles/500px_square/public/earthquake_0.jpg?itok=XH9_KtGN\n",
      "start downloading images\n",
      "./img/14new.jpg succesffully saved！\n",
      "http://www.nysm.nysed.gov/common/nysm/files/styles/500px_square/public/mineralofny.jpg?itok=TGCWmL2P\n",
      "start downloading images\n",
      "./img/15new.jpg succesffully saved！\n",
      "http://www.nysm.nysed.gov/common/nysm/files/styles/500px_square/public/longhouse.jpg?itok=MI9JiuCt\n",
      "start downloading images\n",
      "./img/16new.jpg succesffully saved！\n",
      "http://www.nysm.nysed.gov/common/nysm/files/styles/500px_square/public/NYmetropolis-highlight_0.jpg?itok=dmG484bx\n",
      "start downloading images\n",
      "./img/17new.jpg succesffully saved！\n",
      "http://www.nysm.nysed.gov/common/nysm/files/styles/500px_square/public/St_Paul%27s_Chapel_sunny_jeh%20path%20gray.jpg?itok=O6bk9xfC\n",
      "start downloading images\n",
      "./img/18new.jpg succesffully saved！\n",
      "http://www.nysm.nysed.gov/common/nysm/files/styles/500px_square/public/carouselclosest.jpg?itok=1J_i8qQA\n",
      "start downloading images\n",
      "./img/19new.jpg succesffully saved！\n",
      "http://www.nysm.nysed.gov/common/nysm/files/styles/500px_square/public/WTC%20tower.jpg?itok=yP6Y-XxL\n",
      "start downloading images\n",
      "./img/20new.jpg succesffully saved！\n",
      "http://www.nysm.nysed.gov/common/nysm/files/styles/500px_square/public/wtc-survivors-sq.jpg?itok=Dv7ZQUdN\n",
      "start downloading images\n",
      "./img/21new.jpg succesffully saved！\n"
     ]
    }
   ],
   "source": [
    "header = {\n",
    "'Referer': 'http://www.nysm.nysed.gov/exhibitions',\n",
    "'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.132 Safari/537.36'\n",
    "}\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "#url_path = 'https://www.dpm.org.cn/lights/royal/p/'\n",
    "url = 'http://www.nysm.nysed.gov/exhibitions'\n",
    "url_all=[]\n",
    "j = 0\n",
    "data = requests.get(url,headers=header).content.decode('utf8')\n",
    "soup = BeautifulSoup(data,'html.parser')   \n",
    "\n",
    "urldiv = soup.find_all('div',{'class':'{'class':'css-1l4spti'}) \n",
    "#print(urldiv)      \n",
    "\n",
    "for urltemp in urldiv:\n",
    "    url_find = urltemp.'https://www.nytimes.com'+ url.a['href']\n",
    "    url_all.append(url_find)\n",
    "    j = j+1\n",
    "    #new_url = url_find[:4]+url_find[5:]\n",
    "    print(url_find)      \n",
    "    imgs = requests.get(url_find,headers=header)     \n",
    "    file_name = \"./img/\"+str(j)+\"new.jpg\"\n",
    "    print('start downloading images') \n",
    "    f = open(file_name, 'ab') \n",
    "    f.write(imgs.content) \n",
    "    print(file_name, 'succesffully saved！') \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. news website  multidimension data\n",
    "https://www.shobserver.com (chinese)\n",
    "https://www.nytimes.com/section/technology(english)\n",
    "### 2.1 design\n",
    "### 2.2 scraping the list page\n",
    "### 2.3 save to file\n",
    "### 2.4 scraping the detail page\n",
    "### 2.5 loop to collect all info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\"\n",
    "#  create header infomation\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "#getting header information\n",
    "header = {\n",
    "'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.132 Safari/537.36'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 design\n",
    "### 2.2 scraping the list page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['After Sparring, NASA and SpaceX Declare a Shared Mission', '2,200 Viewed Germany Shooting Before Twitch Removed Post', 'Tech Giants Shift Profits to Avoid Taxes. There’s a Plan to Stop Them.', 'Without Naming Huawei, E.U. Warns Against 5G Firms From ‘Hostile’ Powers', 'Chinese Media’s Attacks on Apple and N.B.A. Help Inflame Nationalism', 'Lithium-Ion Batteries Work Earns Nobel Prize in Chemistry for 3 Scientists', 'Blizzard Sets Off Backlash for Penalizing Hearthstone Gamer in Hong Kong', 'Behind Amazon’s Sudden Change in Its Film Strategy', 'Facebook’s Hands-Off Approach to Political Speech Gets Impeachment Test', 'Can a Jean Jacket Revive Wearable Technology?']\n"
     ]
    }
   ],
   "source": [
    "#  design:inspect webpage infomation,is a list or a detail page\n",
    "url = 'https://www.nytimes.com/section/technology'\n",
    "title_all=[]\n",
    "intr_all=[]\n",
    "data = requests.get(url,headers=header).content.decode('utf8')\n",
    "soup = BeautifulSoup(data,'html.parser')    \n",
    "titlediv = soup.find_all('h2',{'class':'css-1j9dxys e1xfvim30'})      \n",
    "#print(titlediv)\n",
    "#title\n",
    "for title in titlediv:\n",
    "    title_find = title.text.strip()\n",
    "    title_all.append(title_find)\n",
    "print(title_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### practice \n",
    "how to find introduction information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p class=\"css-1echdzn e1xfvim31\">The space agency’s administrator, Jim Bridenstine, met Elon Musk at SpaceX headquarters on Thursday to review progress toward launching NASA astronauts.</p>, <p class=\"css-1echdzn e1xfvim31\">The live-streaming platform, owned by Amazon, has struggled to police content as it is posted.</p>, <p class=\"css-1echdzn e1xfvim31\">Countries have clashed in recent years over how — and where — to tax companies that operate across borders, particularly those that sell online.</p>, <p class=\"css-1echdzn e1xfvim31\">In a security report, the bloc noted the potential for cyberattacks but stopped short of citing any particular providers.</p>, <p class=\"css-1echdzn e1xfvim31\">Outlets are trying to intimidate multinational companies into toeing the party line while Beijing tries to rein in the Hong Kong protests.</p>, <p class=\"css-1echdzn e1xfvim31\">John B. Goodenough, M. Stanley Whittingham and Akira Yoshino were recognized for research that has “laid the foundation of a wireless, fossil fuel-free society.”</p>, <p class=\"css-1echdzn e1xfvim31\">The gaming company suspended the player and made him forfeit his prize money after he expressed support for the protest movement in Hong Kong.</p>, <p class=\"css-1echdzn e1xfvim31\">After poor box-office numbers for Mindy Kaling’s “Late Night,” the company shrank its ambitious release plan for a big fall movie, “The Aeronauts.”</p>, <p class=\"css-1echdzn e1xfvim31\">The company’s handling of a Trump campaign ad with unsubstantiated accusations about Joseph Biden foreshadows a continuing fight over misinformation.</p>, <p class=\"css-1echdzn e1xfvim31\">Lessons have been learned from the unpopularity of Google Glass.</p>]\n",
      "['The space agency’s administrator, Jim Bridenstine, met Elon Musk at SpaceX headquarters on Thursday to review progress toward launching NASA astronauts.', 'The live-streaming platform, owned by Amazon, has struggled to police content as it is posted.', 'Countries have clashed in recent years over how — and where — to tax companies that operate across borders, particularly those that sell online.', 'In a security report, the bloc noted the potential for cyberattacks but stopped short of citing any particular providers.', 'Outlets are trying to intimidate multinational companies into toeing the party line while Beijing tries to rein in the Hong Kong protests.', 'John B. Goodenough, M. Stanley Whittingham and Akira Yoshino were recognized for research that has “laid the foundation of a wireless, fossil fuel-free society.”', 'The gaming company suspended the player and made him forfeit his prize money after he expressed support for the protest movement in Hong Kong.', 'After poor box-office numbers for Mindy Kaling’s “Late Night,” the company shrank its ambitious release plan for a big fall movie, “The Aeronauts.”', 'The company’s handling of a Trump campaign ad with unsubstantiated accusations about Joseph Biden foreshadows a continuing fight over misinformation.', 'Lessons have been learned from the unpopularity of Google Glass.']\n"
     ]
    }
   ],
   "source": [
    "#getting introduction information\n",
    "intr_all=[]\n",
    "## introduction\n",
    "intrdiv =soup.find_all('p',{'class':'css-1echdzn e1xfvim31'}) \n",
    "for intr in intrdiv:\n",
    "    intr_find =  intr.text.strip()\n",
    "    intr_all.append(intr_find)\n",
    "print(intrdiv)\n",
    "print(intr_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### practice\n",
    "\n",
    "how to add url list?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.nytimes.com/2019/10/10/science/nasa-spacex-elon-musk.html', 'https://www.nytimes.com/2019/10/09/business/twitch-germany-shooting.html', 'https://www.nytimes.com/2019/10/09/us/politics/tech-giants-taxes-oecd.html', 'https://www.nytimes.com/2019/10/09/world/europe/eu-huawei-report.html', 'https://www.nytimes.com/2019/10/09/world/asia/china-apple-nba-hong-kong.html', 'https://www.nytimes.com/2019/10/09/science/nobel-prize-chemistry.html', 'https://www.nytimes.com/2019/10/09/world/asia/blizzard-hearthstone-hong-kong.html', 'https://www.nytimes.com/2019/10/09/business/media/amazon-studios-movie-releases.html', 'https://www.nytimes.com/2019/10/08/technology/facebook-trump-biden-ad.html', 'https://www.nytimes.com/2019/10/08/style/can-a-jean-jacket-revive-the-wearable.html']\n"
     ]
    }
   ],
   "source": [
    "#getting list \n",
    "url_all=[]\n",
    "## introduction\n",
    "urldiv = soup.find_all('div',{'class':'css-1l4spti'})\n",
    "for url in urldiv:\n",
    "    url_find ='https://www.nytimes.com' + url.a['href']\n",
    "    url_all.append(url_find)\n",
    "print(url_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########save to file\n",
    "result_temp = {'news_url':url_all,\n",
    "   'news_title':title_all,\n",
    "   'news_intro':intr_all}\n",
    "result_datafram = DataFrame(result_temp)\n",
    "result_datafram.to_csv('./excel/new.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                             news_url  \\\n",
       "0  https://www.nytimes.com/2019/10/10/science/nas...   \n",
       "1  https://www.nytimes.com/2019/10/09/business/tw...   \n",
       "2  https://www.nytimes.com/2019/10/09/us/politics...   \n",
       "3  https://www.nytimes.com/2019/10/09/world/europ...   \n",
       "4  https://www.nytimes.com/2019/10/09/world/asia/...   \n",
       "5  https://www.nytimes.com/2019/10/09/science/nob...   \n",
       "6  https://www.nytimes.com/2019/10/09/world/asia/...   \n",
       "7  https://www.nytimes.com/2019/10/09/business/me...   \n",
       "8  https://www.nytimes.com/2019/10/08/technology/...   \n",
       "9  https://www.nytimes.com/2019/10/08/style/can-a...   \n",
       "\n",
       "                                          news_title  \\\n",
       "0  After Sparring, NASA and SpaceX Declare a Shar...   \n",
       "1  2,200 Viewed Germany Shooting Before Twitch Re...   \n",
       "2  Tech Giants Shift Profits to Avoid Taxes. Ther...   \n",
       "3  Without Naming Huawei, E.U. Warns Against 5G F...   \n",
       "4  Chinese Media’s Attacks on Apple and N.B.A. He...   \n",
       "5  Lithium-Ion Batteries Work Earns Nobel Prize i...   \n",
       "6  Blizzard Sets Off Backlash for Penalizing Hear...   \n",
       "7  Behind Amazon’s Sudden Change in Its Film Stra...   \n",
       "8  Facebook’s Hands-Off Approach to Political Spe...   \n",
       "9      Can a Jean Jacket Revive Wearable Technology?   \n",
       "\n",
       "                                          news_intro  \n",
       "0  The space agency’s administrator, Jim Bridenst...  \n",
       "1  The live-streaming platform, owned by Amazon, ...  \n",
       "2  Countries have clashed in recent years over ho...  \n",
       "3  In a security report, the bloc noted the poten...  \n",
       "4  Outlets are trying to intimidate multinational...  \n",
       "5  John B. Goodenough, M. Stanley Whittingham and...  \n",
       "6  The gaming company suspended the player and ma...  \n",
       "7  After poor box-office numbers for Mindy Kaling...  \n",
       "8  The company’s handling of a Trump campaign ad ...  \n",
       "9  Lessons have been learned from the unpopularit...  >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_datafram.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 scraping the detail page\n",
    "### practice\n",
    "\n",
    "how to download each list detail?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<div class=\"css-75y64v e16638kd1\"><time class=\"css-1sbuyqj e16638kd4\" datetime=\"2019-10-10T09:00:04-04:00\">Oct. 10, 2019</time><time class=\"css-233int e16638kd5\" datetime=\"2019-10-10T19:19:04-04:00\">Updated <span class=\"css-epvm6\">7:19 p.m. ET</span></time></div>]\n",
      "2019-10-10T09:00:04-04:00\n",
      "[<span class=\"css-1baulvz last-byline\" itemprop=\"name\">Kenneth Chang</span>]\n",
      "Kenneth Chang\n"
     ]
    }
   ],
   "source": [
    "#####down load time and author info\n",
    "time2_all=[]\n",
    "title2_all=[]\n",
    "author2_all = []\n",
    "url1 = 'https://www.nytimes.com/2019/10/10/science/nasa-spacex-elon-musk.html'\n",
    "\n",
    "data = requests.get(url1,headers=header).content.decode('utf8')\n",
    "soup = BeautifulSoup(data,'html.parser')    \n",
    "#time\n",
    "timediv = soup.find_all('div',{'class':'css-75y64v e16638kd1'})\n",
    "for time in timediv:\n",
    "    time_find =time.time['datetime']\n",
    "#    time2_all.append(time_find)\n",
    "print(timediv)\n",
    "print(time_find)    \n",
    "\n",
    "\n",
    "#author\n",
    "authordiv = soup.find_all('span',{'class':'css-1baulvz last-byline'})\n",
    "for author in authordiv:\n",
    "    author_find =author.text.strip()\n",
    "#    author_all.append(author_find)\n",
    "print(authordiv)\n",
    "print(author_find)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 loop to collect all info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "['2019-10-10T09:00:04-04:00', '2019-10-09T19:40:23-04:00', '2019-10-09T08:30:08-04:00', '2019-10-09T07:13:03-04:00', '2019-10-09T05:50:48-04:00', '2019-10-09T05:14:30-04:00']\n",
      "['Kenneth Chang', 'Tiffany Hsu', 'Jim Tankersley', 'Matina Stevis-Gridneff', 'Javier C. Hernández', 'Ivan Penn', 'Daniel Victor', 'Nicole Sperling', 'Cecilia Kang']\n"
     ]
    }
   ],
   "source": [
    "# loop \n",
    "# -*- coding: utf-8 -*-\"\n",
    "#collecting all detail info from the list of url\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "# header = {\n",
    "# 'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.143 Safari/537.36',\n",
    "# 'Connection': 'keep-alive',\n",
    "# 'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'\n",
    "# }\n",
    "\n",
    "n=len(url_all)\n",
    "author_a = []\n",
    "time_a = []\n",
    "for i in range(0,n-1):\n",
    "    data = requests.get(url_all[i],headers=header).content.decode('utf8')\n",
    "    soup = BeautifulSoup(data,'html.parser')    \n",
    "    timediv = soup.find_all('div',{'class':'css-75y64v e16638kd1'})      \n",
    "    for time in timediv:\n",
    "        time_find = time.time['datetime']\n",
    "        time_a.append(time_find)\n",
    "\n",
    "    authordiv = soup.find_all('span',{'class':'css-1baulvz last-byline'})      \n",
    "    for author in authordiv:\n",
    "        author_find = author.text.strip()\n",
    "        author_a.append(author_find)\n",
    "    #pause_time = random.randint(1,5)\n",
    "    #time.sleep(pause_time)\n",
    "print(n)\n",
    "print(time_a)\n",
    "print(author_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'author_a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3b7424726b7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#save in files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'news_author'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mauthor_a\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'news_time'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtime_a\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'author_a' is not defined"
     ]
    }
   ],
   "source": [
    "#save in files\n",
    "data = {'news_author':author_a,'news_time':time_a}\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(data)\n",
    "# df.to_excel('new.xlsx') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# more to go on ? analysis take only 10% of the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
